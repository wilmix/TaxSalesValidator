# Instrucciones de Copilot para Web Scraping y Descarga CSV

##  Objetivo del Proyecto

Crear un script de Python minimalista, robusto y as铆ncrono (usando asyncio y playwright.async_api) que implemente el siguiente flujo en la p谩gina de impuestos.gob.bo:

### Flujo del Proyecto

1. Navegar e iniciar sesi贸n con credenciales espec铆ficas.
2. Navegar al m贸dulo "Registro de Ventas".
3. Seleccionar el mes de SEPTIEMBRE como periodo de b煤squeda.
4. Descargar el reporte en formato CSV.
5. Procesar el archivo CSV con Pandas.
6. Comparar/Validar la informaci贸n de ventas con un sistema de inventario local.
7. **(OPCIONAL)** Sincronizar datos validados al sistema contable SAS (con --sync-sas flag).

### Fases Implementadas

- **Fase 1**: Descarga y procesamiento de datos SIAT (web scraping + CUF extraction)
- **Fase 2**: Consulta de base de datos de inventario local (MySQL)
- **Fase 3**: Comparaci贸n y validaci贸n (SIAT vs Inventario)
- **Fase 4**: Sincronizaci贸n a sistema contable SAS (opcional, atomic transactions)

##  Principios Fundamentales (KISS, DRY, SOLID)

### KISS (Keep It Simple, Stupid)

- **Asincron铆a Clara**: El c贸digo debe usar playwright.async_api y asyncio de la manera m谩s legible posible.
- **Funciones At贸micas**: Cada funci贸n debe ejecutar un solo paso del flujo de forma clara (e.g., login(), navigate_to_reports(), download_csv()).

### DRY (Don't Repeat Yourself)

- **Configuraci贸n nica**: Los selectores (getByRole, locator), la URL base y las credenciales NO deben estar hardcodeados en la l贸gica del scraper. Deben ser pasados como argumentos o cargados desde un 煤nico punto de configuraci贸n.
- **Cierre de Recursos**: Asegurar que el contexto del navegador y el navegador mismo se cierren siempre, idealmente usando async with para manejo autom谩tico.

### SOLID - Single Responsibility Principle (SRP)

El script debe estar dividido en bloques l贸gicos principales, estrictamente separados:

**Core Modules (Phases 1-3):**
1. **config.py**: Almacena selectores, credenciales y configuraci贸n general.
2. **web_scraper.py / WebScraper**: Contiene solo la l贸gica de interacci贸n web (Playwright).
3. **file_manager.py / FileManager**: Contiene solo la l贸gica de manejo de archivos CSV (guardar, limpiar, verificar).
4. **data_processor.py / DataProcessor**: Contiene solo la l贸gica de lectura y preparaci贸n del DataFrame de Pandas.
5. **sales_validator.py / SalesValidator**: Contiene solo la l贸gica de comparaci贸n de filas entre el CSV y los datos de inventario local.

**SAS Integration Modules (Phase 4):**
6. **sas_connector.py / SasConnector**: Conexi贸n y operaciones de base de datos MySQL (SAS) con transacciones at贸micas.
7. **sas_mapper.py / SasMapper**: Transformaci贸n de datos SIAT a formato sales_registers (35 campos).
8. **sas_syncer.py / SasSyncer**: Orquestaci贸n del sync (prerequisites check, transform, upsert, stats).

##  Convenci贸n de Nombres (DRY)

**MANDATORIO**: Todo el c贸digo (nombres de archivos, m贸dulos, clases, funciones y variables) debe estar escrito en ingl茅s utilizando snake_case o PascalCase seg煤n corresponda. (Ej: def download_report_csv en lugar de def descargar_reporte_csv).

##  Pautas T茅cnicas

- **Librer铆as**: playwright.async_api, pathlib, pandas.
- **Locators**: Utiliza los locators generados por Codegen (getByRole, locator) ya que son robustos, pero aseg煤rate de pasarlos como variables/configuraci贸n.
- **Descarga**: Usa el patr贸n robusto page.waitForEvent('download') para capturar la descarga de CSV. La descarga debe guardarse en una ruta definida por pathlib.
- **Manejo de Errores**: Incluir manejo de excepciones (try/except) para fallas de navegaci贸n o errores de autenticaci贸n.